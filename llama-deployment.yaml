apiVersion: v1
items:
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    labels:
      app: llama2-7b
    name: llama2-7b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    selector:
      matchLabels:
        component: llama2-7b-layer
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          component: llama2-7b-layer
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: TRUSS_SECRET_huggingface_api_token
            value: hf_uN
          image: us-central1-docker.pkg.dev/epam-394023/llm-repo/llama2-7b
          imagePullPolicy: Always
          name: llama2-7b-container
          ports:
          - containerPort: 8080
            protocol: TCP
          resources:
            limits:
              nvidia.com/gpu: "1"
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        shareProcessNamespace: false
        terminationGracePeriodSeconds: 30
kind: List
metadata:
  resourceVersion: ""
